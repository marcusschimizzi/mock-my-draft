---
phase: 01-data-updates
plan: 02
type: execute
wave: 2
depends_on: ['01']
files_modified:
  - apps/draft-api/src/dtos/data-import.dto.ts
  - apps/draft-api/src/services/data-import-service.ts
  - apps/draft-api/src/services/data-versions-service.ts
  - apps/draft-api/src/controllers/data-imports.controller.ts
  - apps/draft-api/src/routes/data-imports.routes.ts
  - apps/draft-api/src/jobs/daily-data-import.job.ts
  - apps/draft-api/src/main.ts
  - package.json
autonomous: true
user_setup:
  - service: slack
    why: 'Notify admins when data import validation fails'
    env_vars:
      - name: DATA_IMPORT_ALERT_WEBHOOK
        source: 'Slack -> Apps -> Incoming Webhooks -> Copy webhook URL'
    dashboard_config:
      - task: 'Create Incoming Webhook for data import alerts'
        location: 'Slack -> Apps -> Incoming Webhooks'

must_haves:
  truths:
    - 'Users see player data and rankings sourced from the latest published data version.'
    - 'Admin can trigger a manual import and see whether it succeeded or failed.'
    - 'Daily import runs on schedule and keeps the last good data if a run fails.'
    - 'User-facing UI shows a Last updated timestamp for the current dataset.'
  artifacts:
    - path: 'apps/draft-api/src/services/data-import-service.ts'
      provides: 'Versioned import pipeline with validation'
    - path: 'apps/draft-api/src/routes/data-imports.routes.ts'
      provides: 'Manual import and status endpoints'
    - path: 'apps/draft-api/src/jobs/daily-data-import.job.ts'
      provides: 'Scheduled daily import job'
  key_links:
    - from: 'apps/draft-api/src/routes/data-imports.routes.ts'
      to: 'apps/draft-api/src/services/data-import-service.ts'
      via: 'controller action'
      pattern: 'runManualImport'
    - from: 'apps/draft-api/src/jobs/daily-data-import.job.ts'
      to: 'apps/draft-api/src/services/data-import-service.ts'
      via: 'scheduled job'
      pattern: 'runScheduledImport'
---

<objective>
Build the import pipeline, manual trigger endpoints, and daily scheduler for data refreshes.

Purpose: Make daily and manual imports create a validated snapshot without risking live data.
Output: Import service, admin/public endpoints, and cron-based scheduler.
</objective>

<execution_context>
@~/.config/opencode/get-shit-done/workflows/execute-plan.md
@~/.config/opencode/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-data-updates/01-CONTEXT.md
@.planning/phases/01-data-updates/01-RESEARCH.md

@apps/draft-api/src/database/models/player.ts
@apps/draft-api/src/database/models/player-ranking.ts
@apps/draft-api/src/database/models/source.ts
@apps/draft-api/src/database/models/source-article.ts
@apps/draft-api/src/main.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement versioned data import service</name>
  <files>
    apps/draft-api/src/dtos/data-import.dto.ts
    apps/draft-api/src/services/data-import-service.ts
    apps/draft-api/src/services/data-versions-service.ts
  </files>
  <action>
    Define a DataImportPayloadDto describing the JSON input: players with name, position, college, measurements, and rankings with overallRank and positionRank. Implement DataImportService with methods runManualImport and runScheduledImport that call a shared import flow. The flow should read `apps/data-collector/data/${DRAFT_IMPORT_YEAR}_draft_data.json` (default year = current year) and map to Player entities and PlayerRanking entities. Create or reuse a Source named "System Import" and a SourceArticle per run with a unique url like `system://data-import/${timestamp}` so PlayerRanking can attach to a valid SourceArticle. Validate required fields (name, position, overallRank) and reject invalid entries before publish. Use AppDataSource.manager.transaction with repository.save chunking (chunk 1000) to insert players and rankings tied to the new DataVersion. Mark DataVersion status failed and keep prior active version on validation or transaction failure. On success, set DataVersion as active, set publishedAt, and update playerCount/rankingCount. Call a DataVersionsService cleanup method to remove versions older than 7 days.
    Create a DataImportLog entry when the import begins (status pending, startedAt, source), update it on validation failure with completedAt, status failed, errorSummary, and counts, and update it on success with status published, completedAt, and counts. Use the same log for both manual and scheduled runs so the status endpoint can return the latest log. When validation or transaction fails, post a Slack webhook notification to DATA_IMPORT_ALERT_WEBHOOK with the failure summary and version id, but continue returning the failure response even if the webhook fails.
  </action>
  <verify>yarn nx lint draft-api</verify>
  <done>Running the import service creates a new active DataVersion and audit log with counts.</done>
</task>

<task type="auto">
  <name>Task 2: Add manual import + status endpoints</name>
  <files>
    apps/draft-api/src/controllers/data-imports.controller.ts
    apps/draft-api/src/routes/data-imports.routes.ts
    apps/draft-api/src/main.ts
  </files>
  <action>
    Create a DataImportsController with handlers getStatus (public) and runManualImport (admin-only). getStatus should return lastUpdated (active DataVersion publishedAt), activeVersionId, playerCount, rankingCount, and the latest DataImportLog status. runManualImport should call DataImportService.runManualImport and return the new status. Wire routes under `/api/data-imports` with GET `/status` (no auth) and POST `/manual` (authenticate + requireAdmin). Register the router in `apps/draft-api/src/main.ts`.
  </action>
  <verify>curl -s http://localhost:3333/api/data-imports/status</verify>
  <done>Manual import endpoint triggers a new DataVersion and status endpoint returns lastUpdated info.</done>
</task>

<task type="auto">
  <name>Task 3: Schedule daily import job</name>
  <files>
    apps/draft-api/src/jobs/daily-data-import.job.ts
    apps/draft-api/src/main.ts
    package.json
  </files>
  <action>
    Add node-cron dependency. Create a daily-data-import.job.ts that schedules `0 5 * * *` with timezone America/New_York and calls DataImportService.runScheduledImport. Log start/end and errors. Register the job after database initialization in main.ts so it starts once. Ensure the job does not run until AppDataSource is initialized.
  </action>
  <verify>yarn nx lint draft-api</verify>
  <done>Daily import job is registered and logs scheduling on API startup.</done>
</task>

</tasks>

<verification>
- Manual import endpoint returns status and cron scheduling is configured for 5am ET.
</verification>

<success_criteria>

- Manual and scheduled imports create new active data versions without breaking existing data.
  </success_criteria>

<output>
After completion, create `.planning/phases/01-data-updates/01-02-SUMMARY.md`
</output>
